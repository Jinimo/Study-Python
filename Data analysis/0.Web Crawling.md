# Web Crawling
- 웹 페이지 정보 가져오는 방법
- 과도한 데이터 수집은 서버에 무리 및 보안 문제 발생

```python
 ! pip install 라이브러리명
```
 - ! : 콘솔창에 해당 명령어 실행 (콘솔 창에서 실행시 제외)
 - pip : 파이썬 라이브러리 설치 명령어
 - pip install 라이브러리명 : 지정 라이브러리 컴퓨터에 설치   
-------------------
 - `.get()`  
 - `.page_source`
 - ``
-------------------
 ## 1. selenium
 - Chrome,  Internet Explorer, Safari 등 다양한 브라우저에서 사용 가능 
 - selenium으로 작동하는 Chrome driver -> 별도 파일 다운로드 필요 
	*  Chrome 버전 확인 -> 운영체제, Chrome 버전과 일치하는 Chrome driver 파일 찾고 다운 

 0. 명령어
  - `driver.find_elements_by_css_selector('조건')` : 원하는 조건의 태그 찾기 (BeautifulSoup 별도 사용 필요 X)
    
    * 조건 : 태그명/ id 값/ 부모 태그 등의 구조 정보 (CSS Selector)   
    
    
 1. selenium  라이브러리 설치
 ``` python
 ! pip install selenium
 ```
 2.  selenium 라이브러리의 webdriver 불러오기
 ```python
 from selenium import webdriver
 ```
3. Chrome driver 실행
```python
from selenium import webdriver
driver = webdriver.Chrome('Chrome driver 파일 경로/파일명.exe')
```
4.  웹 페이지 접속 (Chrome 브라우저 이용)
```python
url = 'https://www.google.com/'
driver.get(url)
```
5. 웹 페이지 HTML 다운로드
```python
html = driver.page_source
```
-------------------


 ## 2. BeautifulSoup 

  0. 명령어
  - `.select('조건)`
    * `.select('태그명)`
    *  `.select('속성값')` -> `.select('id 값)` / `.select('class명)`
       * `class 속성` : 서식 지정 하기위해 사용. HTML 내 동일한  class명 여러번 사용 가능
       * `id 값` : 특정 대상 지정. HTML 내 한번만 사용 가능 -> id 값 활용하여 태그 검색 용이
    *  `.select('태그명.속성값)`

  

  1. bs4 패키지 설치
``` python
!ip install bs4
```
  2. HTML 해석

```python
from bs4 import BeautifulSoup as bs

# 변수에 들어있는 특정 문자열 정보 -> HTML 형식 맞데 해석
soup = bs(html, 'html.parswe') 
```
 3. 태그 선택 - `.slect('조건')` 사용 

   - 태그 하나만 선택 
```python
tags = soup('조건')
tag_1 = tags[0]   # tags의 첫번째 원소(인덱스 번호 0 )
print(tag_1)
```
  - 태그 하나씩 선택 - 반복문(for)
  ```python
  tags = soup('조건')
  for tag in tags:
    print(tag)
  ```
  4. 태그 정보 가져오기 - `.text`
```python
content = Tag.text       # 화면에 보이는 글 추출
attribute = Tag['속성명']  # 태그 내 속성 값
link =  Tag['href']      #  화면에 안보이는 URL 주소 수집 
```
```python
tags = soup.select('a')  # 태그명 'a'인 태그 선택 
tag = tags[0]            # tags의 인덱스 0번(첫번째) 원소 
content = tag.text       # tag에 저장된 화면에 보이는 텍스트 부분 추출
link =  tag['href']      # tag의 URL 주소 추출
```

  5. selenium + BeautifulSoup 웹 크롤링 정리(Chrome) 예시
```python
#  selenium - 크롬 브라우저 조작 -> 웹페이지 접속
driver = webdriver.Chrome('Chrome driver 파일 경로/파일명.exe')
url = '주소'
driver.get(url)

# BeautifulSoup - 원하는 정보 추출 
html = driver.page_source
soup = bs(html, 'html parser')

tags = soup.select('조건')
for tag in tags: 
  tag_1 = tag.selct('조건')[0].text
  tag_2 = tag.selct('조건')[0].text
  print(tag_1, tag_2)
```

