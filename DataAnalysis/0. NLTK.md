# NLTK

> 자연어 처리 패키지: NLTK (Natural Language Tollkit)



영어(NLTK)



한글(KoNLTK) 





[참조](https://datascienceschool.net/03%20machine%20learning/03.01.01%20NLTK%20%EC%9E%90%EC%97%B0%EC%96%B4%20%EC%B2%98%EB%A6%AC%20%ED%8C%A8%ED%82%A4%EC%A7%80.html#nltk)



```py
## 설치
!pip install nltk
```



### 1. corpus (말뭉치)

>- 자연어 분석 작업 위한 샘플 문서 집합
>- 품사, 형태소 등의 보조적 의미 추가, 쉬운 분석 위한 구조적인 형태로 정리해 놓은 것 포함
>- `corpus`  서브 패키지 -> 다양한 연구용 말뭉치 제공
>- `.download` 명령으로 사용자가 다운 받아 사용 
>- `nltk.download("book")` -> NLTK 패키지 사용자 설명서 말뭉치 다운 

```py
# corpus(말뭉치)
import nltk
nltk.download("book", quiet=True)
from nltk.book import *
```


```py
# 샘플 작품 txt (리스트 구조)
nltk.corpus.gutenberg.fileids() 
# 샘플 작품 중 'austen-emma.txt'
emma_raw = nltk.corpus.gutenberg.raw('austen-emma.txt') 
```



### 2. tokenizing (토큰 생성)

> - 토큰(token): 문자열 단위 
> - 토큰 생성(tokenizing): 문자열을 토큰으로 분리 (문자열의 리스트 출력) 
> - 영문-> 토큰으로 문장, 단어 등 사용 or 정규 표현식 



```py
# 문장
from nltk.tokenize import sent_tokenize
sent_tokenize(emma_raw[:1000])[3]
# 단어
from nltk.tokenize import word_tokenize
word_tokenize(emma_raw[50:100])

# 단어 -> [0-9a-zA-Z_] 영문(대,소)/숫자 제외한 나머지 모두 제거 
from nltk.tokenize import RegexpTokenizer
retokenize = RegexpTokenizer("[\w]+")
retokenize.tokenize(emma_raw[50:100])
```





### 3. morphological analysis (형태소 분석)

> - 형태소(morpheme): 언어학에서 일정한 의미가 있는 가장 작은 말의 단위를 뜻
> - 자연어 처리에서는 토큰으로 형태소 이용 
> - 형태소 분석: 단어의 어근, 접두사, 접미사, 품사 등 다양한 언어적 속성 파악,  이를 이용하여 형태소 찾거나 처리



