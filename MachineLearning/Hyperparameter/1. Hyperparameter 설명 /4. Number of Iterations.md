### Hyperparameter 설명



#### 4) Number of Iterations

> - boosting  iteration 수. 모델 성능, 학습 시간, 램 사용량에 영향 줌.
> - 클수록 train data over fitting
> - 큰 값을 넣은 후, `early stopping`과 함께 사용하는 것이 좋음 



▶️ 사용법

- `early stopping` 없이 iteration 수의 값을 크게 넣으면 → train data over fitting
- train data 전체 사용하여 최종 모형 학습 시
  - `cross validation`을 `early stopping` 과 함께 수행하여 각 `fold` 별 iteration 수를 구한 후, 그 평균 값에 10% 정도 더 큰 값을 사용하는 것이 좋음 

- `early stopping`  보통 50 정도의 값 사용.



|                 | XGBoost                 | Lightgbm                |
| --------------- | ----------------------- | ----------------------- |
|                 | `early_stopping_rounds` | `early_stopping_rounds` |
| sckit-learn API | 동일                    | 동일                    |



✅ 비교 및 설명

|                 | XGBoost        | Lightgbm         |
| --------------- | -------------- | ---------------- |
|                 | `nrounds`      | `num_iterations` |
| sckit-learn API | `n_estimaters` | `n_estimaters`   |



---

[참조]

[XGBoost와 LightGBM 하이퍼파라미터 튜닝 가이드 by psystat](https://psystat.tistory.com/131#head2) 